{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-4e619239092d>:83: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "epoch 1 batch 0 has finished!\n",
      "epoch 1 batch 100 has finished!\n",
      "epoch 1 batch 200 has finished!\n",
      "epoch 1 batch 300 has finished!\n",
      "epoch 1 batch 400 has finished!\n",
      "epoch 1 batch 500 has finished!\n",
      "epoch 1 batch 600 has finished!\n",
      "epoch 1 batch 700 has finished!\n",
      "Train Epoch1：,Loss=2.1368062, Accuracy=0.3226, time=647.7505621910095s\n",
      "epoch 2 batch 0 has finished!\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Mar  5 15:22:17 2019\n",
    "\n",
    "@author: 鲁金川\n",
    "\"\"\"\n",
    "\n",
    "#TensorFlow卷积神经网络识别cifar10数据集\n",
    "\n",
    "#导入cifar10数据集, 标准化特征并且将label转换为one-hot编码\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "(x_img_train, y_label_train), (x_img_test, y_label_test) = cifar10.load_data()\n",
    "L = x_img_train.shape[0]\n",
    "x_img_train_normalize = x_img_train / 255.0\n",
    "x_img_test_normalize = x_img_test / 255.0\n",
    "y_label_train = tf.one_hot(y_label_train, 10, 1, 0)\n",
    "y_label_test = tf.one_hot(y_label_test, 10, 1, 0)\n",
    "#x_img_train_normalize = x_img_train_normalize.reshape(-1, 10000)\n",
    "#x_img_test_normalize = x_img_test_normalize.reshape(-1, 10000)\n",
    "#建立共享函数\n",
    "#权重函数\n",
    "def weight(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev = 0.1), 'W')\n",
    "#偏置函数\n",
    "def bias(shape):\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape), 'b')\n",
    "#卷积运算\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "#池化运算\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "#建立next_batch函数\n",
    "def next_batch(dataSet, batchsize, i):\n",
    "    batch = dataSet[i * batchsize : min([batchsize * (i + 1), L - 1])]\n",
    "    return batch\n",
    "#建立模型\n",
    "#建立输入层\n",
    "with tf.name_scope('Input_Layer'):\n",
    "    x = tf.placeholder('float', shape=[None, 32, 32, 3], name='x')\n",
    "    x_image = x\n",
    "#建立卷积层1\n",
    "with tf.name_scope('C1_Conv'):\n",
    "    W1 = weight([3, 3, 3, 32])\n",
    "    b1 = bias([32])\n",
    "    Conv1 = conv2d(x_image, W1) + b1\n",
    "    C1_conv = tf.nn.relu(Conv1)\n",
    "    C1_conv_dropout = tf.nn.dropout(C1_conv, keep_prob=0.75)\n",
    "#建立池化层1\n",
    "with tf.name_scope('C1_pool'):\n",
    "    C1_pool = max_pool_2x2(C1_conv_dropout)\n",
    "#建立卷积层2\n",
    "with tf.name_scope('C2_Conv'):\n",
    "    W2 = weight([3, 3, 32, 64])\n",
    "    b2 = bias([64])\n",
    "    Conv2 = conv2d(C1_pool, W2) + b2\n",
    "    C2_conv = tf.nn.relu(Conv2)\n",
    "    C2_conv_dropout = tf.nn.dropout(C2_conv, keep_prob=0.75)\n",
    "#建立池化层2\n",
    "with tf.name_scope('C2_pool'):\n",
    "    C2_pool = max_pool_2x2(C2_conv_dropout)\n",
    "#建立平坦层\n",
    "with tf.name_scope('D_Flat'):\n",
    "    D_Flat = tf.reshape(C2_pool, [-1, 8 * 8 * 64])\n",
    "#建立隐藏层\n",
    "with tf.name_scope('D_Hidden_Layer'):\n",
    "    W3 = weight([8 * 8 * 64, 128])\n",
    "    b3 = bias([128])\n",
    "    D_Hidden = tf.nn.relu(tf.matmul(D_Flat, W3) + b3)\n",
    "    D_Hidden_Dropout = tf.nn.dropout(D_Hidden, keep_prob=0.75)\n",
    "#建立输出层\n",
    "with tf.name_scope('Output_Layer'):\n",
    "    W4 = weight([128, 10])\n",
    "    b4 = bias([10])\n",
    "    y_predict = tf.nn.softmax(tf.matmul(D_Hidden_Dropout, W4) + b4)\n",
    "    \n",
    "#定义训练方式\n",
    "with tf.name_scope('optimizer'):\n",
    "    y_label = tf.placeholder('float', shape=[None, 10], name='ylabel')\n",
    "    loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=y_predict, labels=y_label))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.0001).minimize(loss_function)\n",
    "\n",
    "#定义评估模型准确率的方式\n",
    "with tf.name_scope('evaluate_model'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_predict, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "#进行训练\n",
    "#定义训练参数\n",
    "trainEpochs = 5\n",
    "batchSize = 64\n",
    "if np.mod(L, batchSize) == 0:\n",
    "    totalBatchs = int(x_img_train.shape[0] / batchSize)\n",
    "else:\n",
    "    totalBatchs = int(x_img_train.shape[0] / batchSize) + 1\n",
    "epoch_list = [] ; accuracy_list = [] ; loss_list = []\n",
    "from time import time\n",
    "startTime = time()\n",
    "#开始训练\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(trainEpochs):\n",
    "        epochtime = time()\n",
    "        for i in range(totalBatchs):\n",
    "            batch_x = next_batch(x_img_train_normalize, batchSize, i)\n",
    "            batch_y = next_batch(y_label_train, batchSize, i)\n",
    "            #batch_x = sess.run(batch_x)\n",
    "            batch_y = tf.squeeze(batch_y)\n",
    "            batch_y = sess.run(batch_y)\n",
    "            y_label_test = tf.squeeze(y_label_test)\n",
    "            y_label_test = sess.run(y_label_test)\n",
    "            sess.run(optimizer, feed_dict = {x : batch_x, y_label : batch_y})\n",
    "            if (i % 100 == 0):\n",
    "                print('epoch ' + str(epoch + 1)  + ' batch ' + str(i) + ' has finished!')\n",
    "        loss, acc = sess.run([loss_function, accuracy], feed_dict = {x : x_img_test_normalize,\n",
    "                             y_label : y_label_test})\n",
    "        epoch_list.append(epoch)\n",
    "        loss_list.append(loss)\n",
    "        accuracy_list.append(acc)\n",
    "        print('Train Epoch ' + str(epoch + 1) + '：,Loss=' + str(loss) + \n",
    "              ', Accuracy=' + str(acc) + ', time=' + str(time() - epochtime) + 's')\n",
    "    duration = time() - startTime\n",
    "    print('Train Finished Takes:' + str(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
