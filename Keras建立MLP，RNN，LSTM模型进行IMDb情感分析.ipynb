{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立多层感知器模型进行IMDb情感分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们先建立多层感知器模型进行IMDb情感分析，在上一章中，我们完成了数据的预处理，本章我们将建立：\n",
    "\n",
    "**（1）嵌入层** 将数字列表转换成向量列表\n",
    "\n",
    "**（2）多层感知器** 使用多层感知器模型处理向量列表。\n",
    "\n",
    "\n",
    "   $\\bullet$**平坦层：** 共有3200个神经元，因为原来的数字列表一共有100个数字，每个数字转换成32维的向量，所以平坦层有3200个神经元\n",
    "   \n",
    "   $\\bullet$**隐藏层：**一共有256个神经元\n",
    "   \n",
    "   $\\bullet$**输出层：**只有一个神经元，输出1代表正面评价，输出0代表负面评价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入所需模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取IMDb数据集目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #导入正则表达式模块\n",
    "def rm_tags(text): #创建rm_tage函数，输入参数是text文字\n",
    "    re_tag = re.compile(r'<[^>]+>') #创建re_tag为正则表达式变量，赋值为‘<[^>]+>’\n",
    "    return re_tag.sub('', text) #使用re_tag将text文字中符合正则表达式条件的字符替换成空字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_files(filetype):\n",
    "    #创建read_files函数，输入参数为filetype。读取训练数据时传入‘train’，读取测试数据时传入‘test’\n",
    "    path = 'aclImdb/'#设置文件的存取路径\n",
    "    file_list = [] #创建文件列表\n",
    "    \n",
    "    positive_path = path + filetype + '/pos/' #设置正面评价的文件目录为positive_path\n",
    "    for f in os.listdir(positive_path): #用for循环将positive_path目录下的所有文件加入file_list\n",
    "        file_list += [positive_path + f]\n",
    "        \n",
    "    negative_path = path + filetype + '/neg/'#设置负面评价的文件目录为positive_path\n",
    "    for f in os.listdir(negative_path):#用for循环将negative_path目录下的所有文件加入file_list\n",
    "        file_list += [negative_path + f]\n",
    "        \n",
    "    print('read', filetype, 'files:', len(file_list))#显示读取的filetype目录下的文件个数\n",
    "    \n",
    "    all_labels = ([1] * 12500 + [0] * 12500) \n",
    "    #产生all_labels,前12500项是正面，所以产生12500项1的列表，后12500项是负面，所以产生12500项0的列表\n",
    "    \n",
    "    all_texts = [] #设置all_texts为空列表\n",
    "    \n",
    "    '''\n",
    "    用fi读取file_list所有文件，使用打开文件为file_input，使用file_input.readlines()读取文件，\n",
    "    用join连接所有文件内容，然后使用rm_tags删除tag，最后加入all_texrs list\n",
    "    '''\n",
    "    for fi in file_list:\n",
    "        with open(fi, encoding='utf8') as file_input:\n",
    "            all_texts += [rm_tags(' '.join(file_input.readlines()))]\n",
    "            \n",
    "    return all_labels, all_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train files: 25000\n"
     ]
    }
   ],
   "source": [
    "y_train, train_text = read_files('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read test files: 25000\n"
     ]
    }
   ],
   "source": [
    "y_test, test_text = read_files('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer(num_words=2000)\n",
    "token.fit_on_texts(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将影评文字转换成数字列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seq = token.texts_to_sequences(train_text)\n",
    "x_test_seq = token.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "截长补短让数字列表长度都为100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train_seq, 100)\n",
    "x_test = sequence.pad_sequences(x_test_seq, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加入嵌入层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras提供了嵌入层将数字列表转换成向量列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入相关模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把嵌入层加入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(output_dim=32, input_dim= 2000, input_length=100))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数说明\n",
    "\n",
    "output_dim = 32 输出维数是32，我们希望将数字列表转换成32维的向量\n",
    "\n",
    "input_dim = 2000 输入维数是2000，因为之前建立的字典有2000个单词\n",
    "\n",
    "input_length = 100 因为数字列表每一项有100个数字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立多层感知器模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入平坦层，平坦层有3200个神经元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入隐藏层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.35))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入输出层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看模型摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 32)           64000     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               819456    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 883,713\n",
      "Trainable params: 883,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义训练方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.4716 - acc: 0.7627 - val_loss: 0.5328 - val_acc: 0.7584\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.2653 - acc: 0.8907 - val_loss: 0.5224 - val_acc: 0.7796\n",
      "Epoch 3/10\n",
      " - 6s - loss: 0.1603 - acc: 0.9409 - val_loss: 0.5256 - val_acc: 0.8052\n",
      "Epoch 4/10\n",
      " - 6s - loss: 0.0808 - acc: 0.9712 - val_loss: 0.9687 - val_acc: 0.7324\n",
      "Epoch 5/10\n",
      " - 5s - loss: 0.0469 - acc: 0.9847 - val_loss: 1.2965 - val_acc: 0.6978\n",
      "Epoch 6/10\n",
      " - 5s - loss: 0.0349 - acc: 0.9876 - val_loss: 1.2107 - val_acc: 0.7428\n",
      "Epoch 7/10\n",
      " - 6s - loss: 0.0308 - acc: 0.9885 - val_loss: 1.0860 - val_acc: 0.7774\n",
      "Epoch 8/10\n",
      " - 6s - loss: 0.0275 - acc: 0.9903 - val_loss: 1.1285 - val_acc: 0.7862\n",
      "Epoch 9/10\n",
      " - 6s - loss: 0.0230 - acc: 0.9915 - val_loss: 1.2168 - val_acc: 0.7800\n",
      "Epoch 10/10\n",
      " - 6s - loss: 0.0255 - acc: 0.9907 - val_loss: 1.4009 - val_acc: 0.7524\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(x_train, y_train, batch_size=100, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一共执行了10个训练周期，误差越来越小，准确率越来越高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估模型准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 2s 81us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.80916"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准确率是0.81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进行预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 2s 72us/step\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看前10项的预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[: 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用一维数组查看预测结果（使用reshape把二维数组predict转换成以为）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_classes = predict.reshape(-1)\n",
    "predict_classes[: 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看测试数据的预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将创建display_test_Sentiment函数，显示正面评价或负面评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SentimentDict = {1: '正面的', 0: '负面的'}\n",
    "def display_test_Sentiment(i):\n",
    "    print(test_text[i])\n",
    "    print('label真实值：', SentimentDict[y_test[i]], '预测结果：', SentimentDict[predict_classes[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显示第2项预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Miss Cast Away\" is an amusing trifle, which dispenses with serious plot or character development to pack in as many gags as possible. Best enjoyed with a large audience that is open to such entertainments and perhaps, has had a few drinks. Most of the jokes are current-event based so in future years this film may become a time-capsule of turn-of-the-21st-century pop culture references.The 30i to 24p conversion of the footage does create a jerky appearance in some parts, most noticeably the opening aerial shots.The appearance of Micheal Jackson is indeed a strange non-sequiter event. But I, for one, find it encouraging that Mr. Jackson has shown a helpful interest in one of his protégés even after he (the director) has passed from the cute-preteen-boy stage.The effects work is not as bad as one review suggested. Most of it was done by a one-man crew in a brief span of time consisting of animator William Sutton, whose name seems to have been omitted from the IMDb credits. His work is an extraordinary achievement and really helps to fill in the gaps in this movie. I hope he's finally been paid!\n",
      "label真实值： 正面的 预测结果： 负面的\n"
     ]
    }
   ],
   "source": [
    "display_test_Sentiment(2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "第二项数据真实结果是正面的，但是预测结果是负面的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显示第12502项预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seriously Reality Charity TV These producers must think that the masses are full of non-thinkers.These shows are called reality, which means they are suppose to resemble something real, with truth or facts.I suppose the characters are really acting in all the pathetic-ness.At one point I wonder if these type of shows decrease or increase the collective unconsciousness.We live in a world that already contains individuals that are not authentic. Is it necessary to promote an inauthentic way of being?\n",
      "label真实值： 负面的 预测结果： 正面的\n"
     ]
    }
   ],
   "source": [
    "display_test_Sentiment(12502)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "第12502项数据真实值是负面的，预测结果是正面的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看《美女与野兽》影评"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "点击《美女与野兽》的影评界面，拷贝一段影评，并创建变量input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = '''\n",
    "I have seen the animated movie as a kid and always wanted to see it again. Decided to watch this. Maybe this is more \n",
    "enjoyable for kids and at some point I was getting a bit bored but I am glad I watched it till the end because it's a\n",
    "beautiful movie and brought a tear to my eyes a few times.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将影评文字转换成数字列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = token.texts_to_sequences([input_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看数字列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9, 24, 106, 1, 1121, 16, 13, 3, 549, 2, 206, 469, 5, 63, 8, 170, 867, 5, 102, 10, 275, 10, 6, 49, 733, 14, 358, 2, 29, 45, 209, 9, 12, 393, 3, 223, 1095, 17, 9, 240, 1259, 9, 292, 8, 1, 126, 84, 41, 3, 303, 16, 2, 834, 3, 5, 57, 521, 3, 167, 207]]\n"
     ]
    }
   ],
   "source": [
    "print(input_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看数字列表长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增加数字列表使其长度为100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_input_seq = sequence.pad_sequences(input_seq, maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "截长补短后查看数字列表长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pad_input_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用多层感知器进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_result = model.predict_classes(pad_input_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取预测结果中的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_result[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行预测，用之前定义的SentimentDict字典将结果转换成文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'正面的'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SentimentDict[predict_result[0][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "故该评价是正面评价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测《美女与野兽》的影评是正面还是负面的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把前面的命令整理成函数predict_review函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review(input_text):\n",
    "    input_seq = token.texts_to_sequences([input_text])\n",
    "    pad_input_seq = sequence.pad_sequences(input_seq, maxlen=100)\n",
    "    predict_result = model.predict_classes(pad_input_seq)\n",
    "    print(SentimentDict[predict_result[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入影评文字input_text，就可以输出预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测差评"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = '''This movie was completely unnecessary. It does everything from the original animated film but in a \n",
    "bland and boring way. The few things added or changed had no reason to be because the story was already perfect. \n",
    "There was no need for a remake and it was obviously done for some quick cash. They should have just done a rerelease\n",
    "of the original instead of a watered down version.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step\n",
      "负面的\n"
     ]
    }
   ],
   "source": [
    "predict_review(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测好评"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = '''I am writing this review because I'm impressed with such negative feedback in some reviews. I think it \n",
    "is a great remake, it is definitely a matter of taste as I loved feeling like it was the original movie, while it \n",
    "wasn't! It took me back to my childhood and it was just beautiful.\n",
    "\n",
    "If you are looking for a change of script or some kind of surprise you will definitely be disappointed. If you just want \n",
    "to enjoy a magical movie and sing along, you will love it :)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step\n",
      "正面的\n"
     ]
    }
   ],
   "source": [
    "predict_review(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见这两次预测都是比较准确的，我们也可以多做几次尝试\n",
    "\n",
    "《美女与野兽》影评地址\n",
    "https://www.imdb.com/title/tt2771200/reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文字处理时使用较大的字典提取更多文字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们希望可以提高预测的准确率，方法如下：\n",
    "\n",
    "$\\bullet$**增加字典的单词数：**这里我们把原来为2000个单词的词典增加为3800个单词的词典\n",
    "\n",
    "$\\bullet$**增加数字列表截长补短的长度** 原来数字列表的长度是100，这里我们增加为380"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改数据的预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#增加字典的单词量为3800\n",
    "token = Tokenizer(num_words=3800)\n",
    "token.fit_on_texts(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将文字转换为数字列表\n",
    "x_train_seq = token.texts_to_sequences(train_text)\n",
    "x_test_seq = token.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#截长补短，让所有影评所产生的数字序列长度均为380\n",
    "x_train = sequence.pad_sequences(x_train_seq, maxlen=380)\n",
    "x_test = sequence.pad_sequences(x_test_seq, maxlen=380)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(output_dim=32, input_dim=3800, input_length=380))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 380, 32)           121600    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 380, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12160)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               3113216   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 3,235,073\n",
      "Trainable params: 3,235,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 19s - loss: 0.4794 - acc: 0.7567 - val_loss: 0.4975 - val_acc: 0.7850\n",
      "Epoch 2/10\n",
      " - 19s - loss: 0.2008 - acc: 0.9224 - val_loss: 0.5416 - val_acc: 0.7894\n",
      "Epoch 3/10\n",
      " - 19s - loss: 0.0882 - acc: 0.9703 - val_loss: 0.5833 - val_acc: 0.8158\n",
      "Epoch 4/10\n",
      " - 19s - loss: 0.0325 - acc: 0.9908 - val_loss: 0.8868 - val_acc: 0.7732\n",
      "Epoch 5/10\n",
      " - 19s - loss: 0.0123 - acc: 0.9974 - val_loss: 0.8633 - val_acc: 0.8052\n",
      "Epoch 6/10\n",
      " - 22s - loss: 0.0075 - acc: 0.9983 - val_loss: 0.9064 - val_acc: 0.8186\n",
      "Epoch 7/10\n",
      " - 25s - loss: 0.0049 - acc: 0.9989 - val_loss: 1.0689 - val_acc: 0.8024\n",
      "Epoch 8/10\n",
      " - 24s - loss: 0.0049 - acc: 0.9990 - val_loss: 1.3058 - val_acc: 0.7774\n",
      "Epoch 9/10\n",
      " - 24s - loss: 0.0090 - acc: 0.9973 - val_loss: 1.0933 - val_acc: 0.8128\n",
      "Epoch 10/10\n",
      " - 21s - loss: 0.0178 - acc: 0.9938 - val_loss: 1.0341 - val_acc: 0.8212\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(x_train, y_train, batch_size=100, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_input_seq = sequence.pad_sequences(input_seq, maxlen=380)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改predict_review函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_review(input_text):\n",
    "    input_seq = token.texts_to_sequences([input_text])\n",
    "    pad_input_seq = sequence.pad_sequences(input_seq, maxlen=380)\n",
    "    predict_result = model.predict_classes(pad_input_seq)\n",
    "    print(SentimentDict[predict_result[0][0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估模型准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 4s 179us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85488"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型准确率提高到0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Keras RNN模型进行IMDb情感分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本节，我们使用SimpleRNN(units = 16)建立16个神经元的RNN层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入所需模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入嵌入层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(output_dim=32, input_dim= 3800, input_length=380))\n",
    "model.add(Dropout(0.35))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入RNN层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(SimpleRNN(units=16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入隐藏层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.35))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入输出层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看模型摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 380, 32)           121600    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 380, 32)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 16)                784       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               4352      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 126,993\n",
      "Trainable params: 126,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义训练方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 19s - loss: 0.5799 - acc: 0.6846 - val_loss: 0.6068 - val_acc: 0.7380\n",
      "Epoch 2/10\n",
      " - 18s - loss: 0.3596 - acc: 0.8518 - val_loss: 0.6682 - val_acc: 0.6968\n",
      "Epoch 3/10\n",
      " - 18s - loss: 0.2916 - acc: 0.8849 - val_loss: 0.8436 - val_acc: 0.6688\n",
      "Epoch 4/10\n",
      " - 18s - loss: 0.2463 - acc: 0.9038 - val_loss: 0.5229 - val_acc: 0.8024\n",
      "Epoch 5/10\n",
      " - 18s - loss: 0.2115 - acc: 0.9199 - val_loss: 0.5676 - val_acc: 0.8006\n",
      "Epoch 6/10\n",
      " - 18s - loss: 0.1726 - acc: 0.9342 - val_loss: 0.6942 - val_acc: 0.7394\n",
      "Epoch 7/10\n",
      " - 18s - loss: 0.1449 - acc: 0.9447 - val_loss: 0.7185 - val_acc: 0.7776\n",
      "Epoch 8/10\n",
      " - 18s - loss: 0.1360 - acc: 0.9486 - val_loss: 0.8210 - val_acc: 0.7166\n",
      "Epoch 9/10\n",
      " - 18s - loss: 0.1132 - acc: 0.9577 - val_loss: 1.4753 - val_acc: 0.6718\n",
      "Epoch 10/10\n",
      " - 18s - loss: 0.1000 - acc: 0.9626 - val_loss: 0.8901 - val_acc: 0.7710\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(x_train, y_train, batch_size=100, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估模型准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 13s 536us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82428"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型准确率约为0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Keras LSTM模型进行IMDb情感分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码使用LSTM(32)建立32个神经元的LSTM层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(output_dim=32, input_dim=3800, input_length=380))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 380, 32)           121600    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 380, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               8448      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 138,625\n",
      "Trainable params: 138,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 47s - loss: 0.5168 - acc: 0.7394 - val_loss: 0.4622 - val_acc: 0.7732\n",
      "Epoch 2/10\n",
      " - 47s - loss: 0.2899 - acc: 0.8784 - val_loss: 0.4057 - val_acc: 0.8134\n",
      "Epoch 3/10\n",
      " - 46s - loss: 0.2312 - acc: 0.9105 - val_loss: 0.4007 - val_acc: 0.8174\n",
      "Epoch 4/10\n",
      " - 46s - loss: 0.2060 - acc: 0.9220 - val_loss: 0.4735 - val_acc: 0.8082\n",
      "Epoch 5/10\n",
      " - 46s - loss: 0.1799 - acc: 0.9315 - val_loss: 0.4200 - val_acc: 0.8626\n",
      "Epoch 6/10\n",
      " - 47s - loss: 0.1585 - acc: 0.9420 - val_loss: 0.6139 - val_acc: 0.8138\n",
      "Epoch 7/10\n",
      " - 48s - loss: 0.1413 - acc: 0.9496 - val_loss: 0.7020 - val_acc: 0.7872\n",
      "Epoch 8/10\n",
      " - 46s - loss: 0.1221 - acc: 0.9561 - val_loss: 0.4344 - val_acc: 0.8590\n",
      "Epoch 9/10\n",
      " - 46s - loss: 0.1108 - acc: 0.9599 - val_loss: 0.5705 - val_acc: 0.8154\n",
      "Epoch 10/10\n",
      " - 46s - loss: 0.1116 - acc: 0.9592 - val_loss: 0.5445 - val_acc: 0.8402\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(x_train, y_train, batch_size=100, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "评估模型准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 25s 989us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85604"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用LSTM模型准确率提升至0.856"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
