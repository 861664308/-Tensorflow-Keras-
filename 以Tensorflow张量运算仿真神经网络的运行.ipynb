{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以矩阵运算仿真神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow张量运算仿真神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb:\n",
      "[[-0.35999998  0.28      ]]\n",
      "y\n",
      "[[0.   0.28]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "W = tf.Variable([[-0.5, -0.2],\n",
    "                [-0.3, 0.4],\n",
    "                [-0.5, 0.2]])\n",
    "b = tf.Variable([[0.1, 0.2]])\n",
    "XWb = tf.matmul(X, W) + b\n",
    "y = tf.nn.relu(XWb)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('XWb:'); print(sess.run(XWb))\n",
    "    print('y'); print(sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把relu函数换成sigmoid函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb:\n",
      "[[-0.35999998  0.28      ]]\n",
      "y\n",
      "[[0.41095957 0.5695462 ]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "W = tf.Variable([[-0.5, -0.2],\n",
    "                [-0.3, 0.4],\n",
    "                [-0.5, 0.2]])\n",
    "b = tf.Variable([[0.1, 0.2]])\n",
    "XWb = tf.matmul(X, W) + b\n",
    "y = tf.nn.sigmoid(XWb)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('XWb:'); print(sess.run(XWb))\n",
    "    print('y'); print(sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用正态分布随机数生成权重和偏置的初始值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb:\n",
      "[[ 1.0973048  -0.07433489]]\n",
      "y\n",
      "[[1.0973048 0.       ]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1,2]))\n",
    "XWb = tf.matmul(X, W) + b\n",
    "y = tf.nn.relu(XWb)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('XWb:'); print(sess.run(XWb))\n",
    "    print('y'); print(sess.run(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行一次sess.run()可以取的三个Tensorflow变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[-1.1247821  2.0273416]]\n",
      "W\n",
      "[[ 0.48953384 -0.6280775 ]\n",
      " [-2.2979689  -0.31554702]\n",
      " [-0.54036593 -1.0841802 ]]\n",
      "y\n",
      "[[0.        1.2793291]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1,2]))\n",
    "XWb = tf.matmul(X, W) + b\n",
    "y = tf.nn.relu(XWb)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    (_b, _W, _y) = sess.run((b, W, y))\n",
    "    print('b:')\n",
    "    print(_b)\n",
    "    print('W')\n",
    "    print(_W)\n",
    "    print('y')\n",
    "    print(_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 以placeholder传入X值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以placeholder传入1 × 3的二维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[-0.78177404  1.1379212 ]]\n",
      "W:\n",
      "[[-0.83753026  0.20257422]\n",
      " [-0.41789827 -0.5366737 ]\n",
      " [ 0.20537344 -0.36410642]]\n",
      "X:\n",
      "[[0.4 0.2 0.4]]\n",
      "y:\n",
      "[[0.        0.9659736]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "X = tf.placeholder('float', [None, 3])\n",
    "y = tf.nn.relu(tf.matmul(X, W) + b)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4, 0.2, 0.4]])\n",
    "    (_b, _W, _X, _y) = sess.run((b, W, X, y), feed_dict={X: X_array})\n",
    "    print('b:');print(_b);\n",
    "    print('W:');print(_W);\n",
    "    print('X:');print(_X);\n",
    "    print('y:');print(_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以placeholder传入3 × 3二维数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:\n",
      "[[ 0.26287666 -1.9514232 ]]\n",
      "W:\n",
      "[[-0.06532464  1.6326824 ]\n",
      " [ 0.56742567 -0.24778531]\n",
      " [ 0.25008273  0.34466177]]\n",
      "X:\n",
      "[[ 0.4  0.2  0.4]\n",
      " [ 0.3  0.4  0.5]\n",
      " [ 0.3 -0.4  0.5]]\n",
      "y:\n",
      "[[0.45026505 0.        ]\n",
      " [0.5952909  0.        ]\n",
      " [0.14135036 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "X = tf.placeholder('float', [None, 3])\n",
    "y = tf.nn.relu(tf.matmul(X, W) + b)\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4, 0.2, 0.4],\n",
    "                       [0.3, 0.4, 0.5],\n",
    "                       [0.3, -0.4, 0.5]])\n",
    "    (_b, _W, _X, _y) = sess.run((b, W, X, y), feed_dict={X: X_array})\n",
    "    print('b:');print(_b);\n",
    "    print('W:');print(_W);\n",
    "    print('X:');print(_X);\n",
    "    print('y:');print(_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建layer函数以矩阵运算仿真神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer函数\n",
    "\n",
    "我们下面创建layer函数，功能是建立两层的神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(output_dim, input_dim, inputs, activation = None):\n",
    "    #用正态随机数初始化权重和偏置\n",
    "    W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1, output_dim]))\n",
    "    #建立矩阵表达式XWb = (input * W) + b\n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    #计算激活函数值\n",
    "    if activation is None:\n",
    "        outputs = XWb \n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    #返回已经建立的神经网络层\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**输入参数说明**\n",
    "\n",
    "output_dim 输出神经元数量\n",
    "\n",
    "input_dim 输入神经元数量\n",
    "\n",
    "inputs 输入的二维数组placeholdler\n",
    "\n",
    "activation 输入的激活函数，默认是None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用layer函数建立三层类神经网络层\n",
    "\n",
    "我们下面用layer函数建立三层类神经网络，输入层有4个神经元，隐藏层有3个神经元，输出层有两个神经元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Layer X:\n",
      "[[0.4 0.2 0.4 0.5]]\n",
      "hidden Layer h:\n",
      "[[0.         2.088194   0.51277566]]\n",
      "output Layer y:\n",
      "[[0.96104944 0.8929039 ]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder('float', [None, 4]) #第一维设置为None，因为项数不固定\n",
    "h = layer(output_dim=3, input_dim=4, inputs=X, activation=tf.nn.relu)#建立隐藏层h，激活函数为relu\n",
    "y = layer(output_dim=2, input_dim=3, inputs=h)#建立输出层y\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4, 0.2, 0.4, 0.5]])\n",
    "    (layer_X, layer_h, layer_y) = sess.run((X, h, y), feed_dict={X: X_array})\n",
    "    print('input Layer X:');print(layer_X)\n",
    "    print('hidden Layer h:');print(layer_h)\n",
    "    print('output Layer y:');print(layer_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立layer_debug函数显示权重与偏差\n",
    "\n",
    "layer_debug函数与layer函数类似，除了返回outputs外，还返回W和b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(output_dim, input_dim, inputs, activation = None):\n",
    "    #用正态随机数初始化权重和偏置\n",
    "    W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1, output_dim]))\n",
    "    #建立矩阵表达式XWb = (input * W) + b\n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    #计算激活函数值\n",
    "    if activation is None:\n",
    "        outputs = XWb \n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    #返回已经建立的神经网络层\n",
    "    return outputs, W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用layer_debug函数建立三层类神经网络并且显示W和b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Layer X:\n",
      "[[0.4 0.2 0.4 0.5]]\n",
      "W1:\n",
      "[[ 0.93133837  0.5364994  -0.24151532]\n",
      " [-0.13198993 -0.39711076 -0.07884934]\n",
      " [-0.6056461   1.079882   -1.3018585 ]\n",
      " [-0.24656637  1.3235065  -0.70020866]]\n",
      "b1:\n",
      "[[ 0.02427516  0.96883565 -0.42784122]]\n",
      "hidden Layer h:\n",
      "[[0.00487092 2.1977193  0.        ]]\n",
      "W2:\n",
      "[[ 0.03648379  1.2604636 ]\n",
      " [-0.04330066 -0.08184922]\n",
      " [ 0.9764039  -0.12139777]]\n",
      "b2:\n",
      "[[-0.8583216 -1.5012769]]\n",
      "output Layer y:\n",
      "[[-0.9533066 -1.6750188]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder('float', [None, 4]) #第一维设置为None，因为项数不固定\n",
    "h, W1, b1 = layer(output_dim=3, input_dim=4, inputs=X, activation=tf.nn.relu)#建立隐藏层h，激活函数为relu\n",
    "y, W2, b2 = layer(output_dim=2, input_dim=3, inputs=h)#建立输出层y\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4, 0.2, 0.4, 0.5]])\n",
    "    (layer_X, layer_h, layer_y, W1, b1, W2, b2) = sess.run((X, h, y, W1, b1, W2, b2), feed_dict={X: X_array})\n",
    "    print('input Layer X:');print(layer_X)\n",
    "    print('W1:');print(W1)\n",
    "    print('b1:');print(b1)\n",
    "    print('hidden Layer h:');print(layer_h)\n",
    "    print('W2:');print(W2)\n",
    "    print('b2:');print(b2)\n",
    "    print('output Layer y:');print(layer_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
