{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nonNBbI4fFxg",
    "outputId": "9114a201-0af2-4d77-df54-af4cd2fce53d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#TensorFlow卷积神经网络识别cifar10数据集\n",
    "\n",
    "#导入cifar10数据集, 标准化特征并且将label转换为one-hot编码\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "(x_img_train, y_label_train), (x_img_test, y_label_test) = cifar10.load_data()\n",
    "L = x_img_train.shape[0]\n",
    "x_img_train_normalize = x_img_train / 255.0\n",
    "x_img_test_normalize = x_img_test / 255.0\n",
    "y_label_train = tf.one_hot(y_label_train, 10, 1, 0)\n",
    "y_label_test = tf.one_hot(y_label_test, 10, 1, 0)\n",
    "#这里用tf.one_hot得出的是Tensor，必须执行变成一般的变量，否则在后面加入计算图的时候节点会越来越多导致程序变慢\n",
    "with tf.Session() as sess:\n",
    "  y_label_train = sess.run(y_label_train)\n",
    "  y_label_test = sess.run(y_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3xM2t-BPfLAi"
   },
   "outputs": [],
   "source": [
    "#建立共享函数\n",
    "#权重函数\n",
    "def weight(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev = 0.1), 'W')\n",
    "#偏置函数\n",
    "def bias(shape):\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape), 'b')\n",
    "#卷积运算\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "#池化运算\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "#建立next_batch函数\n",
    "def next_batch(dataSet, batchsize, i):\n",
    "    batch = dataSet[i * batchsize : min([batchsize * (i + 1), L - 1])]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "id": "1u_uqBvtfOtI",
    "outputId": "41586dba-08ee-42ea-b66a-652a3875c760"
   },
   "outputs": [],
   "source": [
    "#建立模型\n",
    "#建立输入层\n",
    "with tf.name_scope('Input_Layer'):\n",
    "    x = tf.placeholder('float', shape=[None, 32, 32, 3], name='x')\n",
    "    x_image = x\n",
    "#建立卷积层1\n",
    "with tf.name_scope('C1_Conv'):\n",
    "    W1 = weight([3, 3, 3, 32])\n",
    "    b1 = bias([32])\n",
    "    Conv1 = conv2d(x_image, W1) + b1\n",
    "    C1_conv = tf.nn.relu(Conv1)\n",
    "    C1_conv_dropout = tf.nn.dropout(C1_conv, keep_prob=0.75)\n",
    "#建立池化层1\n",
    "with tf.name_scope('C1_pool'):\n",
    "    C1_pool = max_pool_2x2(C1_conv_dropout)\n",
    "#建立卷积层2\n",
    "with tf.name_scope('C2_Conv'):\n",
    "    W2 = weight([3, 3, 32, 64])\n",
    "    b2 = bias([64])\n",
    "    Conv2 = conv2d(C1_pool, W2) + b2\n",
    "    C2_conv = tf.nn.relu(Conv2)\n",
    "    C2_conv_dropout = tf.nn.dropout(C2_conv, keep_prob=0.75)\n",
    "#建立池化层2\n",
    "with tf.name_scope('C2_pool'):\n",
    "    C2_pool = max_pool_2x2(C2_conv_dropout)\n",
    "#建立平坦层\n",
    "with tf.name_scope('D_Flat'):\n",
    "    D_Flat = tf.reshape(C2_pool, [-1, 8 * 8 * 64])\n",
    "#建立隐藏层\n",
    "with tf.name_scope('D_Hidden_Layer'):\n",
    "    W3 = weight([8 * 8 * 64, 128])\n",
    "    b3 = bias([128])\n",
    "    D_Hidden = tf.nn.relu(tf.matmul(D_Flat, W3) + b3)\n",
    "    D_Hidden_Dropout = tf.nn.dropout(D_Hidden, keep_prob=0.75)\n",
    "#建立输出层\n",
    "with tf.name_scope('Output_Layer'):\n",
    "    W4 = weight([128, 10])\n",
    "    b4 = bias([10])\n",
    "    y_predict = tf.nn.softmax(tf.matmul(D_Hidden_Dropout, W4) + b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "ZhI-CH3WfTFk",
    "outputId": "979b9859-e3ab-43f4-e329-ceb5b22f5889"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-1489547d1fc5>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#定义训练方式\n",
    "with tf.name_scope('optimizer'):\n",
    "    y_label = tf.placeholder('float', shape=[None, 10], name='ylabel')\n",
    "    loss_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=y_predict, labels=y_label))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = 0.0001).minimize(loss_function)\n",
    "\n",
    "#定义评估模型准确率的方式\n",
    "with tf.name_scope('evaluate_model'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_predict, 1), tf.argmax(y_label, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x_5IKy5vfXy0"
   },
   "outputs": [],
   "source": [
    "#进行训练\n",
    "#定义训练参数\n",
    "trainEpochs = 5\n",
    "batchSize = 128\n",
    "if np.mod(L, batchSize) == 0:\n",
    "    totalBatchs = int(x_img_train.shape[0] / batchSize)\n",
    "else:\n",
    "    totalBatchs = int(x_img_train.shape[0] / batchSize) + 1\n",
    "epoch_list = [] ; accuracy_list = [] ; loss_list = []\n",
    "from time import time\n",
    "startTime = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "RckD_RjPfcEA",
    "outputId": "40330fdb-3463-405c-840e-c8caa18ad73e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch 0 has finished!\n",
      "epoch 1 batch 100 has finished!\n",
      "epoch 1 batch 200 has finished!\n",
      "epoch 1 batch 300 has finished!\n",
      "Train Epoch 1：,Loss=2.1378891, Accuracy=0.3284, time=155.64145803451538s\n",
      "epoch 2 batch 0 has finished!\n",
      "epoch 2 batch 100 has finished!\n",
      "epoch 2 batch 200 has finished!\n",
      "epoch 2 batch 300 has finished!\n",
      "Train Epoch 2：,Loss=2.099784, Accuracy=0.3632, time=159.74415802955627s\n",
      "epoch 3 batch 0 has finished!\n",
      "epoch 3 batch 100 has finished!\n",
      "epoch 3 batch 200 has finished!\n",
      "epoch 3 batch 300 has finished!\n",
      "Train Epoch 3：,Loss=2.0727575, Accuracy=0.3853, time=148.66167569160461s\n",
      "epoch 4 batch 0 has finished!\n",
      "epoch 4 batch 100 has finished!\n",
      "epoch 4 batch 200 has finished!\n",
      "epoch 4 batch 300 has finished!\n",
      "Train Epoch 4：,Loss=2.0525484, Accuracy=0.4073, time=147.51935958862305s\n",
      "epoch 5 batch 0 has finished!\n",
      "epoch 5 batch 100 has finished!\n",
      "epoch 5 batch 200 has finished!\n",
      "epoch 5 batch 300 has finished!\n",
      "Train Epoch 5：,Loss=2.0350103, Accuracy=0.4222, time=149.05350351333618s\n",
      "Train Finished Takes:762.4223079681396\n"
     ]
    }
   ],
   "source": [
    "#开始训练\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(trainEpochs):\n",
    "        #tf.get_default_graph().finalize()\n",
    "        epochtime = time()\n",
    "        for i in range(totalBatchs):\n",
    "            batch_x = next_batch(x_img_train_normalize, batchSize, i)\n",
    "            batch_y = next_batch(y_label_train, batchSize, i)\n",
    "            #batch_x = sess.run(batch_x)\n",
    "            batch_y = np.squeeze(batch_y)\n",
    "            #batch_y = sess.run(batch_y)\n",
    "            y_label_test = np.squeeze(y_label_test)\n",
    "            #y_label_test = sess.run(y_label_test)\n",
    "            sess.run(optimizer, feed_dict = {x : batch_x, y_label : batch_y})\n",
    "            if (i % 100 == 0):\n",
    "                print('epoch ' + str(epoch + 1)  + ' batch ' + str(i) + ' has finished!')\n",
    "        loss, acc = sess.run([loss_function, accuracy], feed_dict = {x : x_img_test_normalize,\n",
    "                             y_label : y_label_test})\n",
    "        epoch_list.append(epoch)\n",
    "        loss_list.append(loss)\n",
    "        accuracy_list.append(acc)\n",
    "        print('Train Epoch ' + str(epoch + 1) + '：,Loss=' + str(loss) + \n",
    "              ', Accuracy=' + str(acc) + ', time=' + str(time() - epochtime) + 's')\n",
    "    duration = time() - startTime\n",
    "    print('Train Finished Takes:' + str(duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "sY32WLA1fhwz",
    "outputId": "dbdb4fb9-0855-4a2e-a0cc-d9b02ee288c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'W' has type str, but expected one of: int, long, bool\n",
      "WARNING:tensorflow:Issue encountered when serializing trainable_variables.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'W' has type str, but expected one of: int, long, bool\n"
     ]
    }
   ],
   "source": [
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter('log/cnn',sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TZ6mA0i0fpx_",
    "outputId": "02012e3e-2871-4b61-d4f6-1f313d4c97df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MMrRoiYXf_E9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "cifar10cnn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
